{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "from functools import wraps\n",
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import time\n",
    "\n",
    "import community\n",
    "import networkx as nx\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_consumer = os.environ[\"TWITTER_CONSUMER\"]\n",
    "twitter_consumer_secret = os.environ[\"TWITTER_CONSUMER_SECRET\"]\n",
    "twitter_token = os.environ[\"TWITTER_TOKEN\"]\n",
    "twitter_token_secret = os.environ[\"TWITTER_TOKEN_SECRET\"]\n",
    "\n",
    "auth = tweepy.OAuthHandler(twitter_consumer, twitter_consumer_secret)\n",
    "auth.set_access_token(twitter_token, twitter_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filename = \"tweets.csv\"\n",
    "id_to_screen_name_filename = \"id_to_screen_name.csv\"\n",
    "user_and_friends_filename = \"user_and_friends_ids.csv\"\n",
    "user_to_friend_filename = \"user_to_friend_screen_names.csv\"\n",
    "bios_filename = \"bios.csv\"\n",
    "sentiment_tweets_filename = \"sentiment_tweets.csv\"\n",
    "communities_filename = \"communities.csv\"\n",
    "top_5_communities_filename = \"top_5_communities.csv\"\n",
    "graph_filename = \"security_network.gml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all known screen names so we can use it as a filter.\n",
    "if os.path.exists(tweets_filename):\n",
    "    with open(tweets_filename, newline=\"\") as twitter_file:\n",
    "        csv_reader = csv.DictReader(twitter_file)\n",
    "        known_screen_names = [row[\"screen_name\"] for row in csv_reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"(infosec OR cve OR cybersec OR cybersecurity OR ransomware)\"\n",
    "twitter_filter = \"-filter:retweets\"\n",
    "mininum_favorites = \"min_faves:10\"\n",
    "\n",
    "pattern = re.compile(r\"@\\w+\", re.UNICODE | re.MULTILINE)\n",
    "\n",
    "\n",
    "with  open(tweets_filename, \"a\", newline=\"\") as twitter_file:\n",
    "    csv_writer = csv.writer(twitter_file, quoting=csv.QUOTE_ALL)\n",
    "    header = [\"screen_name\", \"content\", \"mentions\"]\n",
    "    csv_writer.writerow(header)\n",
    "    # fetch 100 pages with 100 tweets per page.\n",
    "    for public_tweets in tweepy.Cursor(api.search, q=f\"{query} {twitter_filter} {mininum_favorites}\", count=100).pages(100):\n",
    "        for tweet in public_tweets:\n",
    "            screen_name = f\"@{tweet.user.screen_name}\"\n",
    "            # skip screen names we have seen before.\n",
    "            if screen_name in known_screen_names:\n",
    "                continue\n",
    "            mentions = pattern.findall(tweet.text)\n",
    "            csv_writer.writerow([screen_name, tweet.text.replace(\"\\n\", \"\\\\n\"), \"|\".join(mentions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry(func=None, wait=900):\n",
    "    \"\"\"retry retries the function after the wait period on a RateLimitError.\n",
    "    \n",
    "    All other errors are raised.\"\"\"\n",
    "    def decorator_retry(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            while True:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except tweepy.RateLimitError:\n",
    "                    print(f\"sleeping for {wait/60}min\", flush=True)\n",
    "                    time.sleep(wait)\n",
    "                except Exception:\n",
    "                    raise\n",
    "        return wrapper\n",
    "\n",
    "\n",
    "    if func is not None:\n",
    "        return decorator_retry(func)\n",
    "\n",
    "    return decorator_retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(msg, filename):\n",
    "    \"\"\"log logs the message to the given filename.\n",
    "    \n",
    "    It will append the message to an existing file.\"\"\"\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = set()\n",
    "with open(tweets_filename, newline=\"\") as twitter_file:\n",
    "    csv_reader = csv.DictReader(twitter_file)\n",
    "    for row in csv_reader:\n",
    "        names.add(row[\"screen_name\"])\n",
    "        for mention in row[\"mentions\"].split(\"|\"):\n",
    "            names.add(mention)\n",
    "\n",
    "# remove empty screen name\n",
    "names.remove(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all known data about screen name and their friends\n",
    "if os.path.exists(user_and_friends_filename):\n",
    "    with open(user_and_friends_filename, newline=\"\") as twitter_file:\n",
    "        csv_reader = csv.DictReader(twitter_file)\n",
    "        friend_list = {row[\"screen_name\"]: row[\"friends_ids\"] for row in csv_reader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@retry\n",
    "def friends_ids(name):\n",
    "    return {name: api.friends_ids(name, count=5000)}\n",
    "\n",
    "print(\"Extract friends ids\", flush=True)\n",
    "for idx, name in enumerate(names):\n",
    "    if idx % 1000 == 0:\n",
    "        print(str(idx) + \" number of name processed\", flush=True)\n",
    "    # if the name is already in the list, we continue\n",
    "    if name in friend_list:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        val = friends_ids(name)\n",
    "    except Exception as e:\n",
    "        log(str(e), \"friends_ids.log\")\n",
    "    else:\n",
    "        friend_list.update(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(user_and_friends_filename, \"w\", newline=\"\") as twitter_file:\n",
    "    header = [\"screen_name\", \"friends_ids\"]\n",
    "    csv_writer = csv.writer(twitter_file, quoting=csv.QUOTE_ALL)\n",
    "    csv_writer.writerow(header)\n",
    "    for screen_name, friends_ids in friend_list.items():\n",
    "        # discard twitter profiles with over 5000 friends - no one can have that many friends!\n",
    "        if len(friends_ids) == 5000:\n",
    "            continue\n",
    "        csv_writer.writerow([screen_name, \"|\".join(str(id_) for id_ in friends_ids)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_friend_ids = list(set(id_ for ids in friend_list.values() for id_ in ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_names = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all known data of id to screen_names\n",
    "if os.path.exists(id_to_screen_name_filename):\n",
    "    with open(id_to_screen_name_filename, newline=\"\") as twitter_file:\n",
    "        csv_reader = csv.DictReader(twitter_file)\n",
    "        screen_names = {row[\"id\"]: row[\"screen_name\"] for row in csv_reader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in screen_names:\n",
    "    try:\n",
    "        # remove all known ids\n",
    "        unique_friend_ids.remove(key)\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry\n",
    "def lookup_users(ids):\n",
    "    return api.lookup_users(ids)\n",
    "\n",
    "print(\"Extract Users from friends ids\", flush=True)\n",
    "for i in range(100, len(unique_friend_ids), 100):\n",
    "    if i % 1000 == 0:\n",
    "        print(str(i) + \" number of id processed\", flush=True)\n",
    "    try:\n",
    "        users = lookup_users(unique_friend_ids[i-100:i])\n",
    "    except Exception as e:\n",
    "        log(str(e), \"lookup_users.log\")\n",
    "    else:\n",
    "        screen_names.update({user.id: user.screen_name for user in users})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(id_to_screen_name_filename, \"w\", newline=\"\") as twitter_file:\n",
    "    header = [\"id\", \"screen_name\"]\n",
    "    csv_writer = csv.writer(twitter_file, quoting=csv.QUOTE_ALL)\n",
    "    csv_writer.writerow(header)\n",
    "    for k, v in screen_names.items():\n",
    "        csv_writer.writerow([k, v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friendly_friend_list = {screen_name: [f\"@{screen_names.get(id_)}\" for id_ in ids] for screen_name, ids in friend_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(user_to_friend_filename, \"w\", newline=\"\") as twitter_file:\n",
    "    header = [\"screen_name\", \"friend_screen_names\"]\n",
    "    csv_writer = csv.writer(twitter_file, quoting=csv.QUOTE_ALL)\n",
    "    csv_writer.writerow(header)\n",
    "    for k, v in friendly_friend_list.items():\n",
    "        csv_writer.writerow([k, \"|\".join(v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(user_to_friend_filename, newline=\"\") as f:\n",
    "    csv_reader = csv.DictReader(f)\n",
    "    screen_name_to_friends = {row[\"screen_name\"]: row[\"friend_screen_names\"].split(\"|\") for row in csv_reader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for screen_name, friends_list in screen_name_to_friends.items():\n",
    "    for friend in friends_list:\n",
    "        if friend in screen_name_to_friends and screen_name in screen_name_to_friends[friend]:\n",
    "            g.add_edge(screen_name, friend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(g, graph_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communities(graph):\n",
    "    partition = community.best_partition(graph)\n",
    "    d = collections.defaultdict(list)\n",
    "    # the community.best_partition function maps nodes to a community number, below we map \n",
    "    for com in set(partition.values()):\n",
    "        for nodes in partition.keys():\n",
    "            if partition[nodes] == com:\n",
    "                d[com].append(nodes)\n",
    "    \n",
    "    return list(d.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_communities = communities(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(communities_filename, \"w\", newline=\"\") as f:\n",
    "    header = [\"community_name\", \"members\"]\n",
    "    csv_writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    for i, com in enumerate(security_communities):\n",
    "        csv_writer.writerow([i, \"|\".join(com)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_largest_communites = sorted(security_communities, key=len, reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(top_5_communities_filename, \"w\", newline=\"\") as f:\n",
    "    header = [\"community_name\", \"members\"]\n",
    "    csv_writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    for i, com in enumerate(top_5_largest_communites):\n",
    "        csv_writer.writerow([i, \"|\".join(com)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_by_communities = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(top_5_communities_filename, newline=\"\") as twitter_file:\n",
    "    csv_reader = csv.DictReader(twitter_file)\n",
    "    members_by_communities = {row[\"community_name\"]: row[\"members\"].split(\"|\") for row in csv_reader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_by_name = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bios_filename, newline=\"\") as f:\n",
    "    csv_reader = csv.DictReader(f)\n",
    "    bio_by_name = {row[\"screen_name\"]: (row[\"bio\"], row[\"location\"]) for row in csv_reader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This member: @akolsuoicauqol caused an error! Shame on thee [{'code': 50, 'message': 'User not found.'}]\n",
      "This member: @ColoradoWinds caused an error! Shame on thee [{'code': 63, 'message': 'User has been suspended.'}]\n",
      "This member: @HormetcAesthetc caused an error! Shame on thee [{'code': 50, 'message': 'User not found.'}]\n",
      "sleeping for 15.0min\n",
      "This member: @Michael27588252 caused an error! Shame on thee [{'code': 50, 'message': 'User not found.'}]\n",
      "This member: @twirlinggoddess caused an error! Shame on thee [{'code': 50, 'message': 'User not found.'}]\n"
     ]
    }
   ],
   "source": [
    "@retry\n",
    "def get_user(member):\n",
    "    return api.get_user(member)\n",
    "\n",
    "for members in members_by_communities.values():\n",
    "    for member in members:\n",
    "        if member in bio_by_name:\n",
    "            continue\n",
    "        try:\n",
    "            user = get_user(member)\n",
    "        except tweepy.TweepError as e:\n",
    "            print(f\"This member: {member} caused an error! Shame on thee {e}\")\n",
    "        else:\n",
    "            bio_by_name[member] = (user.description, user.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bios_filename, \"w\", newline=\"\") as twitter_file:\n",
    "    header = [\"screen_name\", \"bio\", \"location\"]\n",
    "    csv_writer = csv.writer(twitter_file, quoting=csv.QUOTE_ALL)\n",
    "    csv_writer.writerow(header)\n",
    "    for screen_name, (bio, location) in bio_by_name.items():\n",
    "        csv_writer.writerow([screen_name, bio.replace(\"\\n\", \"\\\\n\"), location])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_screen_name = collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sentiment_tweets_filename, newline=\"\") as twitter_file:\n",
    "    csv_reader = csv.DictReader(twitter_file)\n",
    "    for row in csv_reader:\n",
    "        tweets_by_screen_name[row[\"screen_name\"]].append(row[\"tweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This member: @ra6bit caused an error! Shame on thee Not authorized.\n",
      "This member: @ColoradoWinds caused an error! Shame on thee Not authorized.\n",
      "This member: @ZyzzRespecter caused an error! Shame on thee Not authorized.\n",
      "This member: @Michael27588252 caused an error! Shame on thee [{'code': 34, 'message': 'Sorry, that page does not exist.'}]\n"
     ]
    }
   ],
   "source": [
    "@retry\n",
    "def get_user_timeline(member):\n",
    "    return api.user_timeline(member)\n",
    "\n",
    "for members in members_by_communities.values():\n",
    "    for member in members:\n",
    "        if member in tweets_by_screen_name:\n",
    "            continue\n",
    "        try:\n",
    "            statuses = get_user_timeline(member)\n",
    "        except tweepy.TweepError as e:\n",
    "            print(f\"This member: {member} caused an error! Shame on thee {e}\")\n",
    "        else:\n",
    "            tweets_by_screen_name[member] = [status.text for status in statuses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sentiment_tweets_filename, \"w\", newline=\"\") as twitter_file:\n",
    "    header = [\"screen_name\", \"tweets\"]\n",
    "    csv_writer = csv.writer(twitter_file, quoting=csv.QUOTE_ALL)\n",
    "    csv_writer.writerow(header)\n",
    "    for screen_name, tweets in tweets_by_screen_name.items():\n",
    "        for tweet in tweets:\n",
    "            csv_writer.writerow([screen_name, tweet.replace(\"\\n\", \"\\\\n\")])"
   ]
  }
 ]
}