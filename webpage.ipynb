{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02806 Final project \n",
    "> An analysis and visualization for security people using Twitter data.\n",
    "\n",
    "- toc: true \n",
    "- badges: false\n",
    "- author: Peter Bom Jakobsen & Søren Fritzbøger & Yucheng Ren \n",
    "- comments: false\n",
    "- categories: [data_analysis, network]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: The dataset we were used to create the network comes from Twitter, you can view and download them from [here](https://raw.githubusercontent.com/Glorforidor/SocialGraphAssignments/master/twitter_data.zip). The Explainer [notebook]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# Standard libraries.\n",
    "import collections\n",
    "import csv\n",
    "from functools import wraps\n",
    "import math\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "# Third party libraries.\n",
    "from fa2 import ForceAtlas2\n",
    "import networkx as nx\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import texttable\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# Filenames of all the data files which makes up our dataset.\n",
    "tweets_filename = \"tweets.csv\"\n",
    "id_to_screen_name_filename = \"id_to_screen_name.csv\"\n",
    "user_and_friends_filename = \"user_and_friends_ids.csv\"\n",
    "user_to_friend_filename = \"user_to_friend_screen_names.csv\"\n",
    "bios_filename = \"bios.csv\"\n",
    "sentiment_tweets_filename = \"sentiment_tweets.csv\"\n",
    "communities_filename = \"communities.csv\"\n",
    "top_5_communities_filename = \"top_5_communities.csv\"\n",
    "\n",
    "# The saved graph - it is an undirected graph.\n",
    "graph_filename = \"security_network.gml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "g = nx.read_gml(graph_filename)\n",
    "node_sizes = [d for __, d in g.degree]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/community_size.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+\n",
      "| Name             | Friends |\n",
      "+------------------+---------+\n",
      "| @HackingDave     |     216 |\n",
      "+------------------+---------+\n",
      "| @AlyssaM_InfoSec |     198 |\n",
      "+------------------+---------+\n",
      "| @RayRedacted     |     193 |\n",
      "+------------------+---------+\n",
      "| @NicoleBeckwith  |     178 |\n",
      "+------------------+---------+\n",
      "| @DfirDiva        |     170 |\n",
      "+------------------+---------+\n",
      "| @sherrod_im      |     161 |\n",
      "+------------------+---------+\n",
      "| @cybergeekgirl   |     161 |\n",
      "+------------------+---------+\n",
      "| @gabsmashh       |     160 |\n",
      "+------------------+---------+\n",
      "| @LisaForteUK     |     158 |\n",
      "+------------------+---------+\n",
      "| @UK_Daniel_Card  |     154 |\n",
      "+------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "# The top 10 Twitter profiles with most friends - in network term highest degree.\n",
    "table = texttable.Texttable()\n",
    "table.set_cols_align([\"l\", \"r\"])\n",
    "table.set_cols_valign([\"t\", \"b\"])\n",
    "table.add_row([\"Name\", \"Friends\"])\n",
    "\n",
    "for screen_name, degree in sorted(g.degree, key=lambda x: x[1], reverse=True)[:10]:\n",
    "    table.add_row([screen_name, degree])\n",
    "\n",
    "print(table.draw())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/wordcloud1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/wordcloud2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "url = \"https://ndownloader.figstatic.com/files/360592\"\n",
    "words_of_happiness = pd.read_csv(url, delimiter=\"\\t\", skiprows=3)\n",
    "\n",
    "\n",
    "def compute_average_sentiment(tokens):\n",
    "    \"\"\"compute_average_sentiment returns the average sentiment value of the tokens.\n",
    "    \n",
    "    Each token in tokens must be in lowercase.\n",
    "    \"\"\"\n",
    "    sentiment = 0.0\n",
    "    if not len(tokens):\n",
    "        return sentiment\n",
    "\n",
    "    avg = np.nan_to_num(words_of_happiness[words_of_happiness[\"word\"].isin(tokens)][\"happiness_average\"].mean())\n",
    "    return avg\n",
    "\n",
    "\n",
    "communities = {i: set(members) for i, members in enumerate(top_5_largest_communites)}\n",
    "text_of_communities = collections.defaultdict(str)\n",
    "with open(\"sentiment_tweets.csv\", newline=\"\") as f:\n",
    "    csv_reader = csv.DictReader(f)\n",
    "    for row in csv_reader:\n",
    "        for i, members in communities.items():\n",
    "            if row[\"screen_name\"] in members:\n",
    "                text_of_communities[i] += f\" {row['tweets']}\"\n",
    "\n",
    "sentiment_of_communities = {k: compute_average_sentiment(bag_of_words(v)) for k, v in text_of_communities.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "| Community | Sentiment value |\n",
      "+-----------+-----------------+\n",
      "| 1         |            5.46 |\n",
      "+-----------+-----------------+\n",
      "| 2         |            5.44 |\n",
      "+-----------+-----------------+\n",
      "| 3         |            5.52 |\n",
      "+-----------+-----------------+\n",
      "| 4         |            5.51 |\n",
      "+-----------+-----------------+\n",
      "| 5         |            5.46 |\n",
      "+-----------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "table = texttable.Texttable()\n",
    "table.set_cols_align([\"l\", \"r\"])\n",
    "table.set_cols_valign([\"t\", \"b\"])\n",
    "table.set_precision(2)\n",
    "table.add_row([\"Community\", \"Sentiment value\"])\n",
    "\n",
    "for com, sentiment in sorted(sentiment_of_communities.items()):\n",
    "    table.add_row([com+1, sentiment])\n",
    "\n",
    "print(table.draw())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
